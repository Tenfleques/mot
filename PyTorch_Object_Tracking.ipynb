{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python3.6","language":"python","name":"python3.6"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"PyTorch_Object_Tracking.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"YBLbe-3LsOs1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"e10cda41-7a73-486b-bf8e-f8adce67ff46","executionInfo":{"status":"ok","timestamp":1583534474610,"user_tz":-180,"elapsed":33143,"user":{"displayName":"Тендай Мапунгвана Чикаке","photoUrl":"","userId":"14955960297601759197"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vMF9nowBspMq","colab_type":"code","colab":{}},"source":["import os \n","os.chdir(\"/content/drive/My Drive/projects/cv/pytorch_track_people\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0dxy4tEAsT65","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":667},"outputId":"fb66f14f-459e-4e04-82c8-a57793fc7996","executionInfo":{"status":"ok","timestamp":1583534525066,"user_tz":-180,"elapsed":9772,"user":{"displayName":"Тендай Мапунгвана Чикаке","photoUrl":"","userId":"14955960297601759197"}}},"source":["!pip install -r requirements.txt"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.17.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.4.1)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (0.16.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (1.4.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (0.5.0)\n","Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.47.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (6.2.2)\n","Collecting filterpy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/ac8914360460fafa1990890259b7fa5ef7ba4cd59014e782e4ab3ab144d8/filterpy-1.4.5.zip (177kB)\n","\u001b[K     |████████████████████████████████| 184kB 9.6MB/s \n","\u001b[?25hCollecting opencv-python-headless\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/23/5f10b30a48b218a4884bc84188c14381ac71288b210f6f8079a54f7a05e8/opencv_python_headless-4.2.0.32-cp36-cp36m-manylinux1_x86_64.whl (21.6MB)\n","\u001b[K     |████████████████████████████████| 21.6MB 156kB/s \n","\u001b[?25hRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 3)) (3.1.3)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 3)) (2.4.1)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 3)) (1.1.1)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 3)) (2.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->-r requirements.txt (line 5)) (1.12.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->-r requirements.txt (line 6)) (45.2.0)\n","Requirement already satisfied: llvmlite>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->-r requirements.txt (line 6)) (0.31.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 3)) (1.1.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 3)) (2.4.6)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 3)) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 3)) (2.6.1)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->-r requirements.txt (line 3)) (4.4.1)\n","Building wheels for collected packages: filterpy\n","  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for filterpy: filename=filterpy-1.4.5-cp36-none-any.whl size=110451 sha256=d00612716a58b99d04f485c7d8bb558350a29e841252ada8befcc647b105f0ad\n","  Stored in directory: /root/.cache/pip/wheels/c3/0c/dd/e92392c3f38a41371602d99fc77d6c1d42aadbf0c6afccdd02\n","Successfully built filterpy\n","Installing collected packages: filterpy, opencv-python-headless\n","Successfully installed filterpy-1.4.5 opencv-python-headless-4.2.0.32\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["cv2"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"5g-h1Q1_sE4f","colab_type":"code","colab":{}},"source":["from models import *\n","from utils import *\n","\n","import os, sys, time, datetime, random\n","import torch\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","from torch.autograd import Variable\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","from PIL import Image\n","\n","import cv2\n","from sort import *"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"74xQLK13sE4u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"60240c42-ccb1-446a-e28b-f10faaff071d","executionInfo":{"status":"ok","timestamp":1583534527131,"user_tz":-180,"elapsed":2032,"user":{"displayName":"Тендай Мапунгвана Чикаке","photoUrl":"","userId":"14955960297601759197"}}},"source":["config_path='config/yolov3.cfg'\n","weights_path='/content/drive/My Drive/weights/yolov3.weights'\n","class_path='config/coco.names'\n","img_size=416\n","conf_thres=0.8\n","nms_thres=0.4\n","\n","# Load model and weights\n","model = Darknet(config_path, img_size=img_size)\n","model.load_weights(weights_path)\n","model.cuda()\n","model.eval()\n","classes = utils.load_classes(class_path)\n","Tensor = torch.cuda.FloatTensor"],"execution_count":12,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"GnuqOxvRsE43","colab_type":"code","colab":{}},"source":["def detect_image(img):\n","    # scale and pad image\n","    ratio = min(img_size/img.size[0], img_size/img.size[1])\n","    imw = round(img.size[0] * ratio)\n","    imh = round(img.size[1] * ratio)\n","    img_transforms = transforms.Compose([ transforms.Resize((imh, imw)),\n","         transforms.Pad((max(int((imh-imw)/2),0), max(int((imw-imh)/2),0), max(int((imh-imw)/2),0), max(int((imw-imh)/2),0)),\n","                        (128,128,128)),\n","         transforms.ToTensor(),\n","         ])\n","    # convert image to Tensor\n","    image_tensor = img_transforms(img).float()\n","    image_tensor = image_tensor.unsqueeze_(0)\n","    input_img = Variable(image_tensor.type(Tensor))\n","    # run inference on the model and get detections\n","    with torch.no_grad():\n","        detections = model(input_img)\n","        detections = utils.non_max_suppression(detections, 80, conf_thres, nms_thres)\n","    return detections[0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CFbFpTqmvMGn","colab_type":"code","colab":{}},"source":["videopath = '/content/drive/My Drive/data/videos/track/1080p/park_run.webm'\n","sec = 406"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SVcE4SXgsE4-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":632},"outputId":"94d89ff4-4bb9-498d-d85b-156280819301","executionInfo":{"status":"ok","timestamp":1583535684174,"user_tz":-180,"elapsed":1159043,"user":{"displayName":"Тендай Мапунгвана Чикаке","photoUrl":"","userId":"14955960297601759197"}}},"source":["colors=[(255,0,0),(0,255,0),(0,0,255),(255,0,255),(128,0,0),(0,128,0),(0,0,128),(128,0,128),(128,128,0),(0,128,128)]\n","\n","vid = cv2.VideoCapture(videopath)\n","mot_tracker = Sort() \n","\n","frames = 0\n","\n","fps = vid.get(cv2.CAP_PROP_FPS)\n","\n","delta_time_between_frames = 1/fps if fps else 0.3\n","\n","fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","vid.set(cv2.CAP_PROP_POS_MSEC, sec*1000)\n","ret,frame = vid.read()\n","\n","vw = frame.shape[1]\n","vh = frame.shape[0]\n","print (\"Video size\", vw,vh)\n","\n","ext = \".{}\".format(videopath.split(\".\")[-1])\n","\n","outvideo = cv2.VideoWriter(videopath.replace(ext, \"-det.mp4\"),fourcc,20.0,(vw,vh))\n","\n","starttime = time.time()\n","while(ret):\n","    vid.set(cv2.CAP_PROP_POS_MSEC, sec*1000)\n","    ret, frame = vid.read()\n","    if not ret:\n","        break\n","\n","    frames += 1\n","    sec += delta_time_between_frames\n","    \n","    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","    pilimg = Image.fromarray(frame)\n","    detections = detect_image(pilimg)\n","\n","    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n","    img = np.array(pilimg)\n","    pad_x = max(img.shape[0] - img.shape[1], 0) * (img_size / max(img.shape))\n","    pad_y = max(img.shape[1] - img.shape[0], 0) * (img_size / max(img.shape))\n","    unpad_h = img_size - pad_y\n","    unpad_w = img_size - pad_x\n","    if detections is not None:\n","        tracked_objects = mot_tracker.update(detections.cpu())\n","\n","        unique_labels = detections[:, -1].cpu().unique()\n","        n_cls_preds = len(unique_labels)\n","        for x1, y1, x2, y2, obj_id, cls_pred in tracked_objects:\n","            box_h = int(((y2 - y1) / unpad_h) * img.shape[0])\n","            box_w = int(((x2 - x1) / unpad_w) * img.shape[1])\n","            y1 = int(((y1 - pad_y // 2) / unpad_h) * img.shape[0])\n","            x1 = int(((x1 - pad_x // 2) / unpad_w) * img.shape[1])\n","            color = colors[int(obj_id) % len(colors)]\n","            cls = classes[int(cls_pred)]\n","            cv2.rectangle(frame, (x1, y1), (x1+box_w, y1+box_h), color, 4)\n","            cv2.rectangle(frame, (x1, y1-35), (x1+len(cls)*19+80, y1), color, -1)\n","            cv2.putText(frame, cls + \"-\" + str(int(obj_id)), (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 3)\n","\n","    outvideo.write(frame)\n","\n","totaltime = time.time()-starttime\n","print(frames, \"frames\", totaltime/frames, \"s/frame\")\n","outvideo.release()\n"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Video size 1920 1080\n"],"name":"stdout"},{"output_type":"stream","text":["/content/drive/My Drive/projects/cv/pytorch_track_people/sort.py:32: NumbaWarning: \n","Compilation is falling back to object mode WITH looplifting enabled because Function \"iou\" failed type inference due to: non-precise type pyobject\n","[1] During: typing of argument at /content/drive/My Drive/projects/cv/pytorch_track_people/sort.py (37)\n","\n","File \"sort.py\", line 37:\n","def iou(bb_test,bb_gt):\n","    <source elided>\n","  \"\"\"\n","  xx1 = np.maximum(bb_test[0], bb_gt[0])\n","  ^\n","\n","  @jit\n","/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"iou\" was compiled in object mode without forceobj=True.\n","\n","File \"sort.py\", line 33:\n","@jit\n","def iou(bb_test,bb_gt):\n","^\n","\n","  state.func_ir.loc))\n","/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: \n","Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n","\n","For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n","\n","File \"sort.py\", line 33:\n","@jit\n","def iou(bb_test,bb_gt):\n","^\n","\n","  state.func_ir.loc))\n","/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n","  FutureWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["2196 frames 0.5253906004632974 s/frame\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DfvOlFpzAdv7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}